{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 📊 퀴즈: 가설검정 (1표본 t-검정)\n",
        "\n",
        "---\n",
        "\n",
        "## 🧾 상황(Scenario)\n",
        "한 커피체인점은 뜨거운 음료 Tall size의 기준 용량이 355ml(12oz) 라고 안내하고 있다. 본사는 품질관리를 위해 각 점포가 기준 용량을 잘 지키는지 확인하려고, 200개 지점에 미스터리손님을 보내 아메리카노 Tall 1잔씩 용량을 무작위로 측정했다. 측정 결과(200잔 전체):\n",
        "\n",
        "---\n",
        "\n",
        "## 📌 조사 결과(Sample Summary)\n",
        "표본평균 용량: 351ml\n",
        "표본표준편차: 18ml\n",
        "유의수준: 5%\n",
        "\n",
        "---\n",
        "\n",
        "## 🎯 검정하고 싶은 주장(방향 설정)\n",
        "본사는 “전체적으로 기준(355ml)보다 적게 제공되는 경향이 있는지”를 확인하고자 한다.\n",
        "\n",
        "즉, 관심은 한 방향(**작다**)에 있다:  \n",
        "- **실제 평균 용량은 350ml보다 작다 ( \\( \\mu < 350 \\) )**\n",
        "\n",
        "---\n",
        "\n",
        "# ❓ 문제(Questions)\n",
        "\n",
        "## 1) 가설 설정\n",
        "이 상황에서 **귀무가설( \\(H_0\\) )**과 **대립가설( \\(H_1\\) )**을 올바르게 설정하시오.\n",
        "\n",
        "- \\(H_0\\):  \n",
        "- \\(H_1\\):  \n",
        "\n",
        "---\n",
        "\n",
        "## 2) 양측검정 vs 단측검정\n",
        "이 검정은 **양측검정** / **단측검정** 중 무엇인가?  \n",
        "- 무엇인지 쓰고, **이유를 한 문장으로** 설명하시오.\n",
        "\n",
        "---\n",
        "\n",
        "## 3) 만약 검정 결과 귀무가설이 기각되었다면, 이를 일상적인 말로 해석하시오.\n",
        "만약 검정 결과 **귀무가설( \\(H_0\\) )이 기각**되었다면, 이를 일상적인 말로 어떻게 해석할 수 있는가?\n",
        "\n",
        "> 힌트: “확실하다/100%” 같은 표현은 피하고  \n",
        "> “통계적으로 유의하다/근거가 있다” 같은 표현을 사용하시오.\n",
        "\n",
        "---\n",
        "\n",
        "## 4) 위 데이터로 t-검정 통계량을 계산해 기각 여부를 판단하시오. (근사로 계산해도 됨)\n",
        "- “광고가 과장되어 실제로 더 적다”를 주장하므로 관심 방향은 **한쪽( \\(<\\) )**이다.\n",
        "- 모집단 표준편차( \\( \\sigma \\) )를 모르는 상태에서 평균을 검정할 때는 보통 **1표본 t-검정**을 사용한다."
      ],
      "metadata": {
        "id": "5AnqSUyhi7oi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F5am4KipjAeF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}